{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"UCD_feature_extraction_part_1.ipynb","provenance":[],"collapsed_sections":["gTQ3p6-GPmng","UOffn3V7Z81f","LxZAViePUSts","ULKMIKacU7Do","2Udov9UFbAq2","pcKahRDncOmB","xBBjgVaxdHXT","mnRfiPSdkL_r","bQIk2X2Lkw90","F31ayIPRlrdL","ziZkY3syuQV-","GwNRG6NZ0gdg","lfHjC5xi6bSo"]},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"gTQ3p6-GPmng"},"source":["## Loading data and libraries\n","For this I  take a few rows of a tweet dataset. "]},{"cell_type":"code","metadata":{"id":"0rJvg65-Ttn2"},"source":["import pandas as pd\n","import tensorflow as tf\n","import nltk\n","import numpy as np\n","import gensim\n","import gensim.downloader as api\n","from tqdm.notebook import tqdm\n","import warnings\n","warnings.filterwarnings('ignore')\n","tqdm.pandas()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"QfhZw3YwU8-T","executionInfo":{"status":"ok","timestamp":1604498083735,"user_tz":-330,"elapsed":61778,"user":{"displayName":"Abhishek Prajapat","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg604IENiNVEYoc-U-T5E_szulyEzqDfmtw1_Gu=s64","userId":"04077743234157551972"}},"outputId":"3b2e1f70-af53-4f5f-98c8-b13b5ee777cb","colab":{"base_uri":"https://localhost:8080/"}},"source":["nltk.download('all')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["[nltk_data] Downloading collection 'all'\n","[nltk_data]    | \n","[nltk_data]    | Downloading package abc to /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/abc.zip.\n","[nltk_data]    | Downloading package alpino to /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/alpino.zip.\n","[nltk_data]    | Downloading package biocreative_ppi to\n","[nltk_data]    |     /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/biocreative_ppi.zip.\n","[nltk_data]    | Downloading package brown to /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/brown.zip.\n","[nltk_data]    | Downloading package brown_tei to /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/brown_tei.zip.\n","[nltk_data]    | Downloading package cess_cat to /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/cess_cat.zip.\n","[nltk_data]    | Downloading package cess_esp to /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/cess_esp.zip.\n","[nltk_data]    | Downloading package chat80 to /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/chat80.zip.\n","[nltk_data]    | Downloading package city_database to\n","[nltk_data]    |     /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/city_database.zip.\n","[nltk_data]    | Downloading package cmudict to /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/cmudict.zip.\n","[nltk_data]    | Downloading package comparative_sentences to\n","[nltk_data]    |     /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/comparative_sentences.zip.\n","[nltk_data]    | Downloading package comtrans to /root/nltk_data...\n","[nltk_data]    | Downloading package conll2000 to /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/conll2000.zip.\n","[nltk_data]    | Downloading package conll2002 to /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/conll2002.zip.\n","[nltk_data]    | Downloading package conll2007 to /root/nltk_data...\n","[nltk_data]    | Downloading package crubadan to /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/crubadan.zip.\n","[nltk_data]    | Downloading package dependency_treebank to\n","[nltk_data]    |     /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/dependency_treebank.zip.\n","[nltk_data]    | Downloading package dolch to /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/dolch.zip.\n","[nltk_data]    | Downloading package europarl_raw to\n","[nltk_data]    |     /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/europarl_raw.zip.\n","[nltk_data]    | Downloading package floresta to /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/floresta.zip.\n","[nltk_data]    | Downloading package framenet_v15 to\n","[nltk_data]    |     /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/framenet_v15.zip.\n","[nltk_data]    | Downloading package framenet_v17 to\n","[nltk_data]    |     /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/framenet_v17.zip.\n","[nltk_data]    | Downloading package gazetteers to /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/gazetteers.zip.\n","[nltk_data]    | Downloading package genesis to /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/genesis.zip.\n","[nltk_data]    | Downloading package gutenberg to /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/gutenberg.zip.\n","[nltk_data]    | Downloading package ieer to /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/ieer.zip.\n","[nltk_data]    | Downloading package inaugural to /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/inaugural.zip.\n","[nltk_data]    | Downloading package indian to /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/indian.zip.\n","[nltk_data]    | Downloading package jeita to /root/nltk_data...\n","[nltk_data]    | Downloading package kimmo to /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/kimmo.zip.\n","[nltk_data]    | Downloading package knbc to /root/nltk_data...\n","[nltk_data]    | Downloading package lin_thesaurus to\n","[nltk_data]    |     /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/lin_thesaurus.zip.\n","[nltk_data]    | Downloading package mac_morpho to /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/mac_morpho.zip.\n","[nltk_data]    | Downloading package machado to /root/nltk_data...\n","[nltk_data]    | Downloading package masc_tagged to /root/nltk_data...\n","[nltk_data]    | Downloading package moses_sample to\n","[nltk_data]    |     /root/nltk_data...\n","[nltk_data]    |   Unzipping models/moses_sample.zip.\n","[nltk_data]    | Downloading package movie_reviews to\n","[nltk_data]    |     /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/movie_reviews.zip.\n","[nltk_data]    | Downloading package names to /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/names.zip.\n","[nltk_data]    | Downloading package nombank.1.0 to /root/nltk_data...\n","[nltk_data]    | Downloading package nps_chat to /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/nps_chat.zip.\n","[nltk_data]    | Downloading package omw to /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/omw.zip.\n","[nltk_data]    | Downloading package opinion_lexicon to\n","[nltk_data]    |     /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/opinion_lexicon.zip.\n","[nltk_data]    | Downloading package paradigms to /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/paradigms.zip.\n","[nltk_data]    | Downloading package pil to /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/pil.zip.\n","[nltk_data]    | Downloading package pl196x to /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/pl196x.zip.\n","[nltk_data]    | Downloading package ppattach to /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/ppattach.zip.\n","[nltk_data]    | Downloading package problem_reports to\n","[nltk_data]    |     /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/problem_reports.zip.\n","[nltk_data]    | Downloading package propbank to /root/nltk_data...\n","[nltk_data]    | Downloading package ptb to /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/ptb.zip.\n","[nltk_data]    | Downloading package product_reviews_1 to\n","[nltk_data]    |     /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/product_reviews_1.zip.\n","[nltk_data]    | Downloading package product_reviews_2 to\n","[nltk_data]    |     /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/product_reviews_2.zip.\n","[nltk_data]    | Downloading package pros_cons to /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/pros_cons.zip.\n","[nltk_data]    | Downloading package qc to /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/qc.zip.\n","[nltk_data]    | Downloading package reuters to /root/nltk_data...\n","[nltk_data]    | Downloading package rte to /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/rte.zip.\n","[nltk_data]    | Downloading package semcor to /root/nltk_data...\n","[nltk_data]    | Downloading package senseval to /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/senseval.zip.\n","[nltk_data]    | Downloading package sentiwordnet to\n","[nltk_data]    |     /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/sentiwordnet.zip.\n","[nltk_data]    | Downloading package sentence_polarity to\n","[nltk_data]    |     /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/sentence_polarity.zip.\n","[nltk_data]    | Downloading package shakespeare to /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/shakespeare.zip.\n","[nltk_data]    | Downloading package sinica_treebank to\n","[nltk_data]    |     /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/sinica_treebank.zip.\n","[nltk_data]    | Downloading package smultron to /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/smultron.zip.\n","[nltk_data]    | Downloading package state_union to /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/state_union.zip.\n","[nltk_data]    | Downloading package stopwords to /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/stopwords.zip.\n","[nltk_data]    | Downloading package subjectivity to\n","[nltk_data]    |     /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/subjectivity.zip.\n","[nltk_data]    | Downloading package swadesh to /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/swadesh.zip.\n","[nltk_data]    | Downloading package switchboard to /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/switchboard.zip.\n","[nltk_data]    | Downloading package timit to /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/timit.zip.\n","[nltk_data]    | Downloading package toolbox to /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/toolbox.zip.\n","[nltk_data]    | Downloading package treebank to /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/treebank.zip.\n","[nltk_data]    | Downloading package twitter_samples to\n","[nltk_data]    |     /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/twitter_samples.zip.\n","[nltk_data]    | Downloading package udhr to /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/udhr.zip.\n","[nltk_data]    | Downloading package udhr2 to /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/udhr2.zip.\n","[nltk_data]    | Downloading package unicode_samples to\n","[nltk_data]    |     /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/unicode_samples.zip.\n","[nltk_data]    | Downloading package universal_treebanks_v20 to\n","[nltk_data]    |     /root/nltk_data...\n","[nltk_data]    | Downloading package verbnet to /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/verbnet.zip.\n","[nltk_data]    | Downloading package verbnet3 to /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/verbnet3.zip.\n","[nltk_data]    | Downloading package webtext to /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/webtext.zip.\n","[nltk_data]    | Downloading package wordnet to /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/wordnet.zip.\n","[nltk_data]    | Downloading package wordnet_ic to /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/wordnet_ic.zip.\n","[nltk_data]    | Downloading package words to /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/words.zip.\n","[nltk_data]    | Downloading package ycoe to /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/ycoe.zip.\n","[nltk_data]    | Downloading package rslp to /root/nltk_data...\n","[nltk_data]    |   Unzipping stemmers/rslp.zip.\n","[nltk_data]    | Downloading package maxent_treebank_pos_tagger to\n","[nltk_data]    |     /root/nltk_data...\n","[nltk_data]    |   Unzipping taggers/maxent_treebank_pos_tagger.zip.\n","[nltk_data]    | Downloading package universal_tagset to\n","[nltk_data]    |     /root/nltk_data...\n","[nltk_data]    |   Unzipping taggers/universal_tagset.zip.\n","[nltk_data]    | Downloading package maxent_ne_chunker to\n","[nltk_data]    |     /root/nltk_data...\n","[nltk_data]    |   Unzipping chunkers/maxent_ne_chunker.zip.\n","[nltk_data]    | Downloading package punkt to /root/nltk_data...\n","[nltk_data]    |   Unzipping tokenizers/punkt.zip.\n","[nltk_data]    | Downloading package book_grammars to\n","[nltk_data]    |     /root/nltk_data...\n","[nltk_data]    |   Unzipping grammars/book_grammars.zip.\n","[nltk_data]    | Downloading package sample_grammars to\n","[nltk_data]    |     /root/nltk_data...\n","[nltk_data]    |   Unzipping grammars/sample_grammars.zip.\n","[nltk_data]    | Downloading package spanish_grammars to\n","[nltk_data]    |     /root/nltk_data...\n","[nltk_data]    |   Unzipping grammars/spanish_grammars.zip.\n","[nltk_data]    | Downloading package basque_grammars to\n","[nltk_data]    |     /root/nltk_data...\n","[nltk_data]    |   Unzipping grammars/basque_grammars.zip.\n","[nltk_data]    | Downloading package large_grammars to\n","[nltk_data]    |     /root/nltk_data...\n","[nltk_data]    |   Unzipping grammars/large_grammars.zip.\n","[nltk_data]    | Downloading package tagsets to /root/nltk_data...\n","[nltk_data]    |   Unzipping help/tagsets.zip.\n","[nltk_data]    | Downloading package snowball_data to\n","[nltk_data]    |     /root/nltk_data...\n","[nltk_data]    | Downloading package bllip_wsj_no_aux to\n","[nltk_data]    |     /root/nltk_data...\n","[nltk_data]    |   Unzipping models/bllip_wsj_no_aux.zip.\n","[nltk_data]    | Downloading package word2vec_sample to\n","[nltk_data]    |     /root/nltk_data...\n","[nltk_data]    |   Unzipping models/word2vec_sample.zip.\n","[nltk_data]    | Downloading package panlex_swadesh to\n","[nltk_data]    |     /root/nltk_data...\n","[nltk_data]    | Downloading package mte_teip5 to /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/mte_teip5.zip.\n","[nltk_data]    | Downloading package averaged_perceptron_tagger to\n","[nltk_data]    |     /root/nltk_data...\n","[nltk_data]    |   Unzipping taggers/averaged_perceptron_tagger.zip.\n","[nltk_data]    | Downloading package averaged_perceptron_tagger_ru to\n","[nltk_data]    |     /root/nltk_data...\n","[nltk_data]    |   Unzipping\n","[nltk_data]    |       taggers/averaged_perceptron_tagger_ru.zip.\n","[nltk_data]    | Downloading package perluniprops to\n","[nltk_data]    |     /root/nltk_data...\n","[nltk_data]    |   Unzipping misc/perluniprops.zip.\n","[nltk_data]    | Downloading package nonbreaking_prefixes to\n","[nltk_data]    |     /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/nonbreaking_prefixes.zip.\n","[nltk_data]    | Downloading package vader_lexicon to\n","[nltk_data]    |     /root/nltk_data...\n","[nltk_data]    | Downloading package porter_test to /root/nltk_data...\n","[nltk_data]    |   Unzipping stemmers/porter_test.zip.\n","[nltk_data]    | Downloading package wmt15_eval to /root/nltk_data...\n","[nltk_data]    |   Unzipping models/wmt15_eval.zip.\n","[nltk_data]    | Downloading package mwa_ppdb to /root/nltk_data...\n","[nltk_data]    |   Unzipping misc/mwa_ppdb.zip.\n","[nltk_data]    | \n","[nltk_data]  Done downloading collection all\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{"tags":[]},"execution_count":2}]},{"cell_type":"code","metadata":{"id":"SUsnrAn0T6Rg"},"source":["df = pd.read_csv('/content/drive/My Drive/NLP/input/tweet_sentiment.csv')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"5zUedSwCUIml","executionInfo":{"status":"ok","timestamp":1604498084679,"user_tz":-330,"elapsed":62711,"user":{"displayName":"Abhishek Prajapat","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg604IENiNVEYoc-U-T5E_szulyEzqDfmtw1_Gu=s64","userId":"04077743234157551972"}},"outputId":"d2138602-373b-4634-9563-bea1583b8bd1","colab":{"base_uri":"https://localhost:8080/","height":110}},"source":["df.head(2)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>textID</th>\n","      <th>text</th>\n","      <th>selected_text</th>\n","      <th>sentiment</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>cb774db0d1</td>\n","      <td>I`d have responded, if I were going</td>\n","      <td>I`d have responded, if I were going</td>\n","      <td>neutral</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>549e992a42</td>\n","      <td>Sooo SAD I will miss you here in San Diego!!!</td>\n","      <td>Sooo SAD</td>\n","      <td>negative</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["       textID  ... sentiment\n","0  cb774db0d1  ...   neutral\n","1  549e992a42  ...  negative\n","\n","[2 rows x 4 columns]"]},"metadata":{"tags":[]},"execution_count":4}]},{"cell_type":"code","metadata":{"id":"RLhD518gUJqC"},"source":["text = df['text'].sample(100) # randomly taking 100 rows"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"UOffn3V7Z81f"},"source":["## Stop Word Removal"]},{"cell_type":"code","metadata":{"id":"LKaYCd3BaCg1"},"source":["stop_words = nltk.corpus.stopwords.words('english')\n","\n","cleaned_text = []\n","\n","for i in text:\n","\n","  cleaned_text.append([word for word in i.split() if word not in stop_words])"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"LxZAViePUSts"},"source":["## Tokenization "]},{"cell_type":"code","metadata":{"id":"KzLZ45aIUxOZ"},"source":["word_tokenized = []\n","tweet_tokenized = []\n","\n","for i in text:\n","  word_tokenized.append(nltk.tokenize.word_tokenize(i))\n","  tweet_tokenized.append(nltk.tokenize.TweetTokenizer().tokenize(i))\n","\n","tensorflow_tokenizer = tf.keras.preprocessing.text.Tokenizer()\n","tensorflow_tokenizer.fit_on_texts(text)\n","sequence = tensorflow_tokenizer.texts_to_sequences(text)\n","tf_tokenized = tensorflow_tokenizer.sequences_to_texts(sequence)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ULKMIKacU7Do"},"source":["## Stemming and Lemmetization"]},{"cell_type":"code","metadata":{"id":"EoxTIcd2YhF8"},"source":["lemmatized = []\n","stemmed = []\n","\n","for i in text:\n","  lemmatized.append(nltk.stem.WordNetLemmatizer().lemmatize(i))\n","  stemmed.append(nltk.stem.SnowballStemmer('english', ignore_stopwords=True).stem(i))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"2Udov9UFbAq2"},"source":["## Bag of Words"]},{"cell_type":"code","metadata":{"id":"3nQrZaOGbGaU"},"source":["from sklearn.feature_extraction.text import CountVectorizer"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"DA_EufiCbbHj"},"source":["bow_uni_gram = CountVectorizer(stop_words=stop_words) # Uni-gram\n","bow_bi_gram = CountVectorizer(stop_words=stop_words, ngram_range=(1,2)) # Uni as well as bi gram (n-gram)\n","bow_uni_gram.fit(text)\n","bow_bi_gram.fit(text);"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"FjGZ-PL7bhsc"},"source":["bow_uni_text = bow_uni_gram.transform(text)\n","bow_bi_text = bow_bi_gram.transform(text)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"pcKahRDncOmB"},"source":["## Tf-idf"]},{"cell_type":"code","metadata":{"id":"99UqKkd-cbAQ"},"source":["from sklearn.feature_extraction.text import TfidfVectorizer"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"w-HbsAsCcfi0"},"source":["tfidf_uni_gram = TfidfVectorizer(stop_words=stop_words) # Uni gram\n","tfidf_bi_gram = TfidfVectorizer(stop_words=stop_words, ngram_range=(1,2)) # Uni as well as bi gram (n-gram)\n","tfidf_uni_gram.fit(text)\n","tfidf_bi_gram.fit(text);"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"KwnF3WQtc7ka"},"source":["tfidf_uni_text = tfidf_uni_gram.transform(text)\n","tfidf_bi_text = tfidf_bi_gram.transform(text)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"xBBjgVaxdHXT"},"source":["## Word2Vec"]},{"cell_type":"code","metadata":{"id":"LG3Plzo7dNus","executionInfo":{"status":"ok","timestamp":1604499111732,"user_tz":-330,"elapsed":171548,"user":{"displayName":"Abhishek Prajapat","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg604IENiNVEYoc-U-T5E_szulyEzqDfmtw1_Gu=s64","userId":"04077743234157551972"}},"outputId":"85d74b11-5b46-4cf5-9c0a-f10e6e65dd78","colab":{"base_uri":"https://localhost:8080/"}},"source":["''' For creating a word2vec we need a large dataset and we have only\n"," taken a few rows so we will create a word2vec using another dataset and use it\n"," for feature extraction , for the sake of knowing we will create word2vec using our own data as well'''\n","\n","dataset = api.load('text8')\n","\n","# There are several other parameters such as \"sg\": 0 for skip-gram and 1 for CBOW\n","# Details can be seen after uncommenting and running the next cell\n","word2vec_model = gensim.models.Word2Vec(sentences=dataset, size=100)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["[==================================================] 100.0% 31.6/31.6MB downloaded\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"HJWzMgtOejQv"},"source":["#?gensim.models.Word2Vec"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"EEGyZbVmfJGU"},"source":["# Creating the embeddings for the text\n","embedded_text = np.zeros((100,100))\n","\n","for index, value in enumerate(text):\n","  sent_vec = np.zeros(100)\n","\n","  for j in value.split():\n","\n","    if j in word2vec_model:\n","      word_vec = word2vec_model.wv[j]\n","    else:\n","      word_vec = np.zeros(100)\n","\n","    sent_vec += word_vec\n","\n","  embedded_text[index] = sent_vec"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"T2fbq6MLhuJ3"},"source":["# Creating Word2Vec using our data\n","our_word2vec_model = gensim.models.Word2Vec(sentences=text, size=20) # Limiting the embedding dimension to 20"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Bew3kmPkmf3m","executionInfo":{"status":"ok","timestamp":1604499279454,"user_tz":-330,"elapsed":1516,"user":{"displayName":"Abhishek Prajapat","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg604IENiNVEYoc-U-T5E_szulyEzqDfmtw1_Gu=s64","userId":"04077743234157551972"}},"outputId":"e04484ff-6d35-48cd-b06f-f5638b408852","colab":{"base_uri":"https://localhost:8080/"}},"source":["text"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["7829                                  that makes me sad...\n","17624    is having a jam session in her room and then s...\n","1787     Hey  wow cheers for the insight ppl  looks FUN...\n","16081     Actually, by the time i get there, the train ...\n","13797    Scratch that. Now we`re watching `marley and m...\n","                               ...                        \n","16876           Im @ the dentist  ....scary people here...\n","10102    On the airport in Philadelphia at the moment, ...\n","12294                                   Painting my room =\n","207        Grabbing coffee from  then making mom breakfast\n","19259    Happy Mother`s Day to all the moms! If you`re ...\n","Name: text, Length: 100, dtype: object"]},"metadata":{"tags":[]},"execution_count":27}]},{"cell_type":"markdown","metadata":{"id":"mnRfiPSdkL_r"},"source":["## Average_word2Vec"]},{"cell_type":"code","metadata":{"id":"KjmP1e88kS-p"},"source":["# Creating the average embeddings for the text\n","embedded_text = np.zeros((100,100))\n","\n","for index, value in enumerate(text):\n","  sent_vec = np.zeros(100)\n","\n","  for j in value.split():\n","\n","    if j in word2vec_model:\n","      word_vec = word2vec_model.wv[j]\n","    else:\n","      word_vec = np.zeros(100)\n","\n","    sent_vec += word_vec\n","\n","  embedded_text[index] = sent_vec / len(value.split())"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"bQIk2X2Lkw90"},"source":["## Tf-idf weighted Word2Vec"]},{"cell_type":"code","metadata":{"id":"DywAGkaplSvQ"},"source":["# Creating the tfidf weighted embeddings for the text\n","\n","# dict key:word and value:tf-idf score\n","word2tfidf = dict(zip(tfidf_uni_gram.get_feature_names(), tfidf_uni_gram.idf_))\n","\n","embedded_text = np.zeros((100,100))\n","\n","for index, value in enumerate(text):\n","  sent_vec = np.zeros(100)\n","\n","  for j in value.split():\n","\n","    if j in word2vec_model:\n","      word_vec = word2vec_model.wv[j]\n","      try:\n","        idf = word2tfidf[j]\n","      except:\n","        idf = 0\n","        \n","      word_vec = word_vec * idf\n","\n","    else:\n","      word_vec = np.zeros(100)\n","\n","    sent_vec += word_vec\n","\n","  embedded_text[index] = sent_vec"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"F31ayIPRlrdL"},"source":["## Glove Embeddings"]},{"cell_type":"code","metadata":{"id":"-XSjEA0RrEVZ","executionInfo":{"status":"ok","timestamp":1604499416754,"user_tz":-330,"elapsed":1103,"user":{"displayName":"Abhishek Prajapat","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg604IENiNVEYoc-U-T5E_szulyEzqDfmtw1_Gu=s64","userId":"04077743234157551972"}},"outputId":"4e142244-f674-4dd6-f375-713e046d36a2","colab":{"base_uri":"https://localhost:8080/"}},"source":["api.info()['models'].keys()"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["dict_keys(['fasttext-wiki-news-subwords-300', 'conceptnet-numberbatch-17-06-300', 'word2vec-ruscorpora-300', 'word2vec-google-news-300', 'glove-wiki-gigaword-50', 'glove-wiki-gigaword-100', 'glove-wiki-gigaword-200', 'glove-wiki-gigaword-300', 'glove-twitter-25', 'glove-twitter-50', 'glove-twitter-100', 'glove-twitter-200', '__testing_word2vec-matrix-synopsis'])"]},"metadata":{"tags":[]},"execution_count":34}]},{"cell_type":"code","metadata":{"id":"JLmcN5xsrZXN","executionInfo":{"status":"ok","timestamp":1604499489577,"user_tz":-330,"elapsed":72034,"user":{"displayName":"Abhishek Prajapat","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg604IENiNVEYoc-U-T5E_szulyEzqDfmtw1_Gu=s64","userId":"04077743234157551972"}},"outputId":"11baac18-5a09-4bb8-fc45-8c466adcf7c4","colab":{"base_uri":"https://localhost:8080/"}},"source":["# For this we will use the 'glove-wiki-gigaword-100'\n","\n","glove_model = api.load('glove-wiki-gigaword-100')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["[==================================================] 100.0% 128.1/128.1MB downloaded\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"oBagHsAprxOP"},"source":["# Creating the embeddings for the text\n","embedded_text = np.zeros((100,100))\n","\n","for index, value in enumerate(text):\n","  sent_vec = np.zeros(100)\n","\n","  for j in value.split():\n","\n","    if j in glove_model:\n","      word_vec = glove_model.wv[j]\n","    else:\n","      word_vec = np.zeros(100)\n","\n","    sent_vec += word_vec\n","\n","  embedded_text[index] = sent_vec"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ziZkY3syuQV-"},"source":["## Fast_text Embeddings"]},{"cell_type":"code","metadata":{"id":"y-d-Of-UuTUO"},"source":["# For this we will use 'fasttext-wiki-news-subwords-300'\n","\n","fast_text_model = api.load('fasttext-wiki-news-subwords-300')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"s3gZM12D0QEV"},"source":["# Creating the embeddings for the text\n","embedded_text = np.zeros((100,300))\n","\n","for index, value in enumerate(text):\n","  sent_vec = np.zeros(300)\n","\n","  for j in value.split():\n","\n","    if j in fast_text_model:\n","      word_vec = fast_text_model.wv[j]\n","    else:\n","      word_vec = np.zeros(300)\n","\n","    sent_vec += word_vec\n","\n","  embedded_text[index] = sent_vec"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"GwNRG6NZ0gdg"},"source":["## Word2Vec and Glove ensembled Embedding"]},{"cell_type":"code","metadata":{"id":"M9N-kzwE0wUM","executionInfo":{"status":"ok","timestamp":1604000359037,"user_tz":-330,"elapsed":735788,"user":{"displayName":"Abhishek Prajapat","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg604IENiNVEYoc-U-T5E_szulyEzqDfmtw1_Gu=s64","userId":"04077743234157551972"}},"outputId":"9cf4a507-0e98-46a2-d4f8-5ed2df2a49a8","colab":{"base_uri":"https://localhost:8080/"}},"source":["ensembled_model = api.load('conceptnet-numberbatch-17-06-300') # this has embeddings for many languages"],"execution_count":null,"outputs":[{"output_type":"stream","text":["[==================================================] 100.0% 1168.7/1168.7MB downloaded\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"d1lWQrTp0-z3"},"source":["# Creating the embeddings for the text\n","embedded_text = np.zeros((100,300))\n","\n","for index, value in enumerate(text):\n","  sent_vec = np.zeros(300)\n","\n","  for j in value.split():\n","\n","    word = '/c/en/' + str(j)\n","\n","    if word in ensembled_model:\n","      word_vec = ensembled_model.wv[word]\n","    else:\n","      word_vec = np.zeros(300)\n","\n","    sent_vec += word_vec\n","\n","  embedded_text[index] = sent_vec"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"lfHjC5xi6bSo"},"source":["## Dynamic Embeddings"]},{"cell_type":"code","metadata":{"id":"5zU74LtV6jN3"},"source":["import tensorflow_hub as hub"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"2zCyepSI6t3v"},"source":["elmo_model = hub.KerasLayer(\"https://tfhub.dev/google/elmo/2\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"mMqBMhmW7KA3"},"source":["elmo_embeddings = elmo_model(np.array(text))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"KBnZLorn7USB","executionInfo":{"status":"ok","timestamp":1604001397444,"user_tz":-330,"elapsed":1517,"user":{"displayName":"Abhishek Prajapat","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg604IENiNVEYoc-U-T5E_szulyEzqDfmtw1_Gu=s64","userId":"04077743234157551972"}},"outputId":"fba813d9-548c-4af6-fca2-285e67ebfaa1","colab":{"base_uri":"https://localhost:8080/"}},"source":["elmo_embeddings.shape"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["TensorShape([100, 1024])"]},"metadata":{"tags":[]},"execution_count":150}]}]}